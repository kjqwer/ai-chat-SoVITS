import os
import json
import random
import sys
import logging
import tempfile
import time
from typing import Optional, List, Dict, Any
from pathlib import Path

import torch
import psutil
import numpy as np
import soundfile as sf
from fastapi import FastAPI, HTTPException, UploadFile, File, Request
from fastapi.responses import FileResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# è®¾ç½®é«˜ä¼˜å…ˆçº§
def set_high_priority():
    """æŠŠå½“å‰ Python è¿›ç¨‹è®¾ä¸º HIGH_PRIORITY_CLASS"""
    if os.name != "nt":
        return # ä»… Windows æœ‰æ•ˆ
    p = psutil.Process(os.getpid())
    try:
        p.nice(psutil.HIGH_PRIORITY_CLASS)
        print("å·²å°†è¿›ç¨‹ä¼˜å…ˆçº§è®¾ä¸º High")
    except psutil.AccessDenied:
        print("æƒé™ä¸è¶³ï¼Œæ— æ³•ä¿®æ”¹ä¼˜å…ˆçº§ï¼ˆè¯·ç”¨ç®¡ç†å‘˜è¿è¡Œï¼‰")

set_high_priority()

# æ·»åŠ è·¯å¾„
now_dir = os.getcwd()
sys.path.append(now_dir)
sys.path.append("%s/GPT_SoVITS" % (now_dir))

# è®¾ç½®æ—¥å¿—çº§åˆ«
logging.getLogger("markdown_it").setLevel(logging.ERROR)
logging.getLogger("urllib3").setLevel(logging.ERROR)
logging.getLogger("httpcore").setLevel(logging.ERROR)
logging.getLogger("httpx").setLevel(logging.ERROR)
logging.getLogger("asyncio").setLevel(logging.ERROR)
logging.getLogger("charset_normalizer").setLevel(logging.ERROR)
logging.getLogger("torchaudio._extension").setLevel(logging.ERROR)

# ç¯å¢ƒå˜é‡è®¾ç½®
if "_CUDA_VISIBLE_DEVICES" in os.environ:
    os.environ["CUDA_VISIBLE_DEVICES"] = os.environ["_CUDA_VISIBLE_DEVICES"]

is_half = eval(os.environ.get("is_half", "True")) and torch.cuda.is_available()
version = model_version = os.environ.get("version", "v2")

# å¯¼å…¥TTSç›¸å…³æ¨¡å—
from TTS_infer_pack.TTS import TTS, TTS_Config
from config import get_weights_names, name2sovits_path, name2gpt_path
from process_ckpt import get_sovits_version_from_path_fast
from tools.i18n.i18n import I18nAuto, scan_language_list

# åˆå§‹åŒ–i18n
language = os.environ.get("language", "Auto")
language = sys.argv[-1] if sys.argv[-1] in scan_language_list() else language
i18n = I18nAuto(language=language)

# è®¾å¤‡æ£€æµ‹
if torch.cuda.is_available():
    device = "cuda"
else:
    device = "cpu"

# è¯­è¨€é…ç½®
dict_language_v1 = {
    "ä¸­æ–‡": "all_zh",
    "è‹±æ–‡": "en",
    "æ—¥æ–‡": "all_ja",
    "ä¸­è‹±æ··åˆ": "zh",
    "æ—¥è‹±æ··åˆ": "ja",
    "å¤šè¯­ç§æ··åˆ": "auto",
}
dict_language_v2 = {
    "ä¸­æ–‡": "all_zh",
    "è‹±æ–‡": "en",
    "æ—¥æ–‡": "all_ja",
    "ç²¤è¯­": "all_yue",
    "éŸ©æ–‡": "all_ko",
    "ä¸­è‹±æ··åˆ": "zh",
    "æ—¥è‹±æ··åˆ": "ja",
    "ç²¤è‹±æ··åˆ": "yue",
    "éŸ©è‹±æ··åˆ": "ko",
    "å¤šè¯­ç§æ··åˆ": "auto",
    "å¤šè¯­ç§æ··åˆ(ç²¤è¯­)": "auto_yue",
}

# åˆ‡åˆ†æ–¹æ³•
cut_method = {
    "ä¸åˆ‡": "cut0",
    "å‡‘å››å¥ä¸€åˆ‡": "cut1",
    "å‡‘50å­—ä¸€åˆ‡": "cut2",
    "æŒ‰ä¸­æ–‡å¥å·ã€‚åˆ‡": "cut3",
    "æŒ‰è‹±æ–‡å¥å·.åˆ‡": "cut4",
    "æŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡": "cut5",
}

# è·å–æ¨¡å‹åˆ—è¡¨
SoVITS_names, GPT_names = get_weights_names()

# åˆå§‹åŒ–TTSé…ç½®
tts_config = TTS_Config("GPT_SoVITS/configs/tts_infer.yaml")
tts_config.device = device
tts_config.is_half = is_half
tts_config.update_version(version)

# åŠ è½½æƒé‡é…ç½®
if os.path.exists("./weight.json"):
    with open("./weight.json", "r", encoding="utf-8") as file:
        weight_data = json.loads(file.read())
        gpt_path = weight_data.get("GPT", {}).get(version, GPT_names[-1] if GPT_names else None)
        sovits_path = weight_data.get("SoVITS", {}).get(version, SoVITS_names[0] if SoVITS_names else None)
else:
    with open("./weight.json", "w", encoding="utf-8") as file:
        json.dump({"GPT": {}, "SoVITS": {}}, file)
    gpt_path = GPT_names[-1] if GPT_names else None
    sovits_path = SoVITS_names[0] if SoVITS_names else None

if gpt_path and isinstance(gpt_path, list):
    gpt_path = gpt_path[0]
if sovits_path and isinstance(sovits_path, list):
    sovits_path = sovits_path[0]

# è®¾ç½®æ¨¡å‹è·¯å¾„
if gpt_path:
    if "ï¼" in gpt_path or "!" in gpt_path:
        gpt_path = name2gpt_path[gpt_path]
    tts_config.t2s_weights_path = gpt_path

if sovits_path:
    if "ï¼" in sovits_path or "!" in sovits_path:
        sovits_path = name2sovits_path[sovits_path]
    tts_config.vits_weights_path = sovits_path

# åˆå§‹åŒ–TTSç®¡é“
tts_pipeline = TTS(tts_config)

# è§’è‰²æ•°æ®åŠ è½½
def load_character_data():
    """åŠ è½½æ‰€æœ‰è§’è‰²çš„éŸ³é¢‘æ•°æ®"""
    character_data = {}
    reference_audios_path = "reference_audios"
    
    if not os.path.exists(reference_audios_path):
        return character_data
    
    # åŠ è½½emotionsç›®å½•
    emotions_path = os.path.join(reference_audios_path, "emotions")
    if os.path.exists(emotions_path):
        for character_name in os.listdir(emotions_path):
            character_dir = os.path.join(emotions_path, character_name)
            if os.path.isdir(character_dir):
                if character_name not in character_data:
                    character_data[character_name] = {"emotions": {}, "randoms": {}}
                
                # éå†è¯­è¨€ç›®å½•
                for lang_dir in os.listdir(character_dir):
                    lang_path = os.path.join(character_dir, lang_dir)
                    if os.path.isdir(lang_path):
                        character_data[character_name]["emotions"][lang_dir] = []
                        
                        # åŠ è½½éŸ³é¢‘æ–‡ä»¶
                        for audio_file in os.listdir(lang_path):
                            if audio_file.endswith('.wav'):
                                # ä»æ–‡ä»¶åæå–æƒ…æ„Ÿå’Œæ–‡æœ¬
                                import re
                                match = re.match(r'ã€(.+?)ã€‘(.+)\.wav', audio_file)
                                if match:
                                    emotion = match.group(1)
                                    text = match.group(2)
                                    audio_path = os.path.join(lang_path, audio_file)
                                    character_data[character_name]["emotions"][lang_dir].append({
                                        "emotion": emotion,
                                        "text": text,
                                        "path": audio_path,
                                    })
    
    # åŠ è½½randomsç›®å½•
    randoms_path = os.path.join(reference_audios_path, "randoms")
    if os.path.exists(randoms_path):
        for character_name in os.listdir(randoms_path):
            character_dir = os.path.join(randoms_path, character_name)
            if os.path.isdir(character_dir):
                if character_name not in character_data:
                    character_data[character_name] = {"emotions": {}, "randoms": {}}
                
                # éå†è¯­è¨€ç›®å½•
                for lang_dir in os.listdir(character_dir):
                    lang_path = os.path.join(character_dir, lang_dir)
                    if os.path.isdir(lang_path):
                        character_data[character_name]["randoms"][lang_dir] = []
                        
                        # åŠ è½½éŸ³é¢‘å’Œlabæ–‡ä»¶å¯¹
                        wav_files = [f for f in os.listdir(lang_path) if f.endswith('.wav')]
                        for wav_file in wav_files:
                            lab_file = wav_file.replace('.wav', '.lab')
                            lab_path = os.path.join(lang_path, lab_file)
                            wav_path = os.path.join(lang_path, wav_file)
                            
                            if os.path.exists(lab_path):
                                try:
                                    with open(lab_path, 'r', encoding='utf-8') as f:
                                        text = f.read().strip()
                                    
                                    character_data[character_name]["randoms"][lang_dir].append({
                                        "text": text,
                                        "path": wav_path,
                                    })
                                except Exception as e:
                                    print(f"Error reading lab file {lab_path}: {e}")
    
    return character_data

def get_default_happy_audio(character_name, character_data, language="ä¸­æ–‡"):
    """è·å–è§’è‰²çš„é»˜è®¤å¼€å¿ƒéŸ³é¢‘"""
    if character_name in character_data and language in character_data[character_name]["emotions"]:
        for audio_info in character_data[character_name]["emotions"][language]:
            if "å¼€å¿ƒ" in audio_info["emotion"] or "happy" in audio_info["emotion"]:
                return audio_info
        # å¦‚æœæ²¡æœ‰å¼€å¿ƒéŸ³é¢‘ï¼Œè¿”å›ç¬¬ä¸€ä¸ªemotionséŸ³é¢‘
        if character_data[character_name]["emotions"][language]:
            return character_data[character_name]["emotions"][language][0]
    
    # å¦‚æœemotionsä¸­æ²¡æœ‰éŸ³é¢‘ï¼Œå°è¯•randoms
    if character_name in character_data and language in character_data[character_name]["randoms"]:
        if character_data[character_name]["randoms"][language]:
            return character_data[character_name]["randoms"][language][0]
    
    return None

# åŠ è½½è§’è‰²æ•°æ®
character_data = load_character_data()

# å…¨å±€çŠ¶æ€
class AppState:
    def __init__(self):
        self.current_sovits_model = sovits_path
        self.current_character = None
        self.current_character_audio = None
        self.dict_language = dict_language_v1 if version == "v1" else dict_language_v2
        
        # é»˜è®¤æ¨ç†é…ç½®
        self.inference_config = {
            "text_lang": "ä¸­æ–‡",
            "prompt_lang": "ä¸­æ–‡", 
            "top_k": 5,
            "top_p": 1.0,
            "temperature": 1.0,
            "text_split_method": "å‡‘å››å¥ä¸€åˆ‡",
            "batch_size": 20,
            "speed_factor": 1.0,
            "ref_text_free": False,
            "split_bucket": True,
            "fragment_interval": 0.3,
            "parallel_infer": True,
            "repetition_penalty": 1.35,
            "sample_steps": 32,
            "super_sampling": False,
        }

app_state = AppState()

# åˆ›å»ºä¸´æ—¶æ–‡ä»¶ç›®å½•
temp_dir = tempfile.mkdtemp(prefix="tts_output_")
print(f"ä¸´æ—¶æ–‡ä»¶ç›®å½•: {temp_dir}")

# Pydanticæ¨¡å‹
class SoVITSModelInfo(BaseModel):
    name: str
    path: str
    is_current: bool

class CharacterInfo(BaseModel):
    name: str
    is_current: bool

class TTSRequest(BaseModel):
    text: str

class InferenceConfigUpdate(BaseModel):
    text_lang: Optional[str] = None
    prompt_lang: Optional[str] = None
    top_k: Optional[int] = None
    top_p: Optional[float] = None
    temperature: Optional[float] = None
    text_split_method: Optional[str] = None
    batch_size: Optional[int] = None
    speed_factor: Optional[float] = None
    ref_text_free: Optional[bool] = None
    split_bucket: Optional[bool] = None
    fragment_interval: Optional[float] = None
    parallel_infer: Optional[bool] = None
    repetition_penalty: Optional[float] = None
    sample_steps: Optional[int] = None
    super_sampling: Optional[bool] = None

# FastAPIåº”ç”¨
app = FastAPI(title="GPT-SoVITS TTS API", version="1.0.0")

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æºï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰HTTPæ–¹æ³•
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰è¯·æ±‚å¤´
)

# æ·»åŠ é™æ€æ–‡ä»¶æœåŠ¡
dist_path = os.path.join(now_dir, "ui", "dist")
if os.path.exists(dist_path):
    # æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•
    app.mount("/static", StaticFiles(directory=dist_path), name="static")
    print(f"å‰ç«¯é™æ€æ–‡ä»¶ç›®å½•: {dist_path}")
else:
    print(f"å‰ç«¯é™æ€æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨: {dist_path}")
    print("è¯·å…ˆæ„å»ºå‰ç«¯é¡¹ç›®: cd ui && pnpm build")

@app.get("/models/sovits", response_model=List[SoVITSModelInfo])
async def get_sovits_models():
    """è·å–SoVITSæ¨¡å‹åˆ—è¡¨å’Œå½“å‰ä½¿ç”¨æ¨¡å‹"""
    models = []
    for model_name in SoVITS_names:
        models.append(SoVITSModelInfo(
            name=model_name,
            path=model_name,
            is_current=(model_name == app_state.current_sovits_model)
        ))
    return models

@app.post("/models/sovits/set")
async def set_sovits_model(model_name: str):
    """è®¾ç½®å½“å‰SoVITSæ¨¡å‹"""
    if model_name not in SoVITS_names:
        raise HTTPException(status_code=404, detail="Model not found")
    
    try:
        # æ›´æ–°æ¨¡å‹è·¯å¾„
        sovits_path = model_name
        if "ï¼" in sovits_path or "!" in sovits_path:
            sovits_path = name2sovits_path[sovits_path]
        
        # è·å–æ¨¡å‹ç‰ˆæœ¬ä¿¡æ¯
        global version, model_version
        version, model_version, if_lora_v3 = get_sovits_version_from_path_fast(sovits_path)
        
        # æ›´æ–°è¯­è¨€å­—å…¸
        app_state.dict_language = dict_language_v1 if version == "v1" else dict_language_v2
        
        # åŠ è½½æ¨¡å‹
        tts_pipeline.init_vits_weights(sovits_path)
        app_state.current_sovits_model = model_name
        
        # ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
        with open("./weight.json", "r") as f:
            data = json.loads(f.read())
            data["SoVITS"][version] = sovits_path
        with open("./weight.json", "w") as f:
            f.write(json.dumps(data))
        
        return {"message": "Model set successfully", "model": model_name}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to set model: {str(e)}")

@app.get("/characters", response_model=List[CharacterInfo])
async def get_characters():
    """è·å–è§’è‰²åˆ—è¡¨å’Œå½“å‰è§’è‰²"""
    characters = []
    for character_name in character_data.keys():
        characters.append(CharacterInfo(
            name=character_name,
            is_current=(character_name == app_state.current_character)
        ))
    return characters

@app.post("/characters/set")
async def set_character(character_name: str):
    """è®¾ç½®å½“å‰è§’è‰²"""
    if character_name not in character_data:
        raise HTTPException(status_code=404, detail="Character not found")
    
    # è‡ªåŠ¨é€‰æ‹©å¼€å¿ƒéŸ³é¢‘
    default_audio = get_default_happy_audio(character_name, character_data, "ä¸­æ–‡")
    if not default_audio:
        raise HTTPException(status_code=404, detail="No audio found for character")
    
    app_state.current_character = character_name
    app_state.current_character_audio = default_audio
    
    return {
        "message": "Character set successfully",
        "character": character_name,
        "audio_path": default_audio["path"],
        "audio_text": default_audio["text"]
    }

@app.post("/tts")
async def text_to_speech(request: TTSRequest):
    """æ–‡æœ¬è½¬è¯­éŸ³"""
    if not app_state.current_character or not app_state.current_character_audio:
        raise HTTPException(status_code=400, detail="No character selected")
    
    try:
        # å‡†å¤‡æ¨ç†å‚æ•°
        seed = random.randint(0, 2**32 - 1)
        audio_info = app_state.current_character_audio
        
        inputs = {
            "text": request.text,
            "text_lang": app_state.dict_language[app_state.inference_config["text_lang"]],
            "ref_audio_path": audio_info["path"],
            "aux_ref_audio_paths": [],
            "prompt_text": audio_info["text"],
            "prompt_lang": app_state.dict_language[app_state.inference_config["prompt_lang"]],
            "top_k": app_state.inference_config["top_k"],
            "top_p": app_state.inference_config["top_p"],
            "temperature": app_state.inference_config["temperature"],
            "text_split_method": cut_method[app_state.inference_config["text_split_method"]],
            "batch_size": app_state.inference_config["batch_size"],
            "speed_factor": app_state.inference_config["speed_factor"],
            "split_bucket": app_state.inference_config["split_bucket"],
            "return_fragment": False,
            "fragment_interval": app_state.inference_config["fragment_interval"],
            "seed": seed,
            "parallel_infer": app_state.inference_config["parallel_infer"],
            "repetition_penalty": app_state.inference_config["repetition_penalty"],
            "sample_steps": app_state.inference_config["sample_steps"],
            "super_sampling": app_state.inference_config["super_sampling"],
        }
        
        # æ‰§è¡Œæ¨ç†ï¼Œè·å–ç”Ÿæˆå™¨ç»“æœ
        for result in tts_pipeline.run(inputs):
            # result æ˜¯ (sampling_rate, audio_data) çš„å…ƒç»„
            sampling_rate, audio_data = result
            break  # åªå–ç¬¬ä¸€ä¸ªç»“æœ
        
        # ç”Ÿæˆä¸´æ—¶æ–‡ä»¶å
        timestamp = int(time.time())
        temp_filename = f"tts_output_{timestamp}_{seed}.wav"
        output_path = os.path.join(temp_dir, temp_filename)
        
        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        sf.write(output_path, audio_data, sampling_rate)
        
        return FileResponse(
            output_path,
            media_type="audio/wav",
            filename=temp_filename,
            headers={"Content-Disposition": f"attachment; filename={temp_filename}"}
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"TTS generation failed: {str(e)}")

@app.get("/config/inference")
async def get_inference_config():
    """è·å–å½“å‰æ¨ç†é…ç½®"""
    return app_state.inference_config

@app.post("/config/inference")
async def update_inference_config(config: InferenceConfigUpdate):
    """æ›´æ–°æ¨ç†é…ç½®"""
    for key, value in config.dict(exclude_unset=True).items():
        if hasattr(app_state.inference_config, key) or key in app_state.inference_config:
            app_state.inference_config[key] = value
    
    return {"message": "Inference config updated", "config": app_state.inference_config}

@app.get("/status")
async def get_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    return {
        "current_sovits_model": app_state.current_sovits_model,
        "current_character": app_state.current_character,
        "current_character_audio": app_state.current_character_audio["text"] if app_state.current_character_audio else None,
        "device": device,
        "version": version,
        "model_version": model_version,
        "temp_dir": temp_dir,
    }

@app.post("/api/save-config")
async def save_config(request: dict):
    """ä¿å­˜AIé…ç½®åˆ°publicç›®å½•"""
    try:
        config_path = os.path.join(dist_path, "ai-config.json")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(config_path), exist_ok=True)
        
        # ä¿å­˜é…ç½®
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(request, f, ensure_ascii=False, indent=2)
        
        return {"message": "é…ç½®ä¿å­˜æˆåŠŸ", "path": config_path}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}")

# å‰ç«¯è·¯ç”±å¤„ç†
@app.get("/", response_class=HTMLResponse)
async def serve_frontend():
    """æœåŠ¡å‰ç«¯é¦–é¡µ"""
    index_path = os.path.join(dist_path, "index.html")
    if os.path.exists(index_path):
        with open(index_path, "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())
    else:
        return HTMLResponse(content="<h1>å‰ç«¯æ–‡ä»¶æœªæ‰¾åˆ°</h1><p>è¯·å…ˆæ„å»ºå‰ç«¯é¡¹ç›®: cd ui && pnpm build</p>")

@app.get("/{path:path}", response_class=HTMLResponse)
async def serve_frontend_routes(path: str):
    """å¤„ç†å‰ç«¯è·¯ç”±ï¼ˆSPAæ¨¡å¼ï¼‰"""
    # æ£€æŸ¥æ˜¯å¦æ˜¯APIè·¯å¾„
    if path.startswith("models/") or path.startswith("characters/") or path.startswith("config/") or path.startswith("tts") or path.startswith("status"):
        # è®©FastAPIå¤„ç†APIè·¯ç”±
        raise HTTPException(status_code=404, detail="API endpoint not found")
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯é™æ€èµ„æº
    static_file_path = os.path.join(dist_path, path)
    if os.path.exists(static_file_path) and os.path.isfile(static_file_path):
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åè¿”å›é€‚å½“çš„MIMEç±»å‹
        if path.endswith('.js'):
            with open(static_file_path, "r", encoding="utf-8") as f:
                return HTMLResponse(content=f.read(), media_type="application/javascript")
        elif path.endswith('.css'):
            with open(static_file_path, "r", encoding="utf-8") as f:
                return HTMLResponse(content=f.read(), media_type="text/css")
        elif path.endswith(('.png', '.jpg', '.jpeg', '.gif', '.ico')):
            return FileResponse(static_file_path)
        else:
            with open(static_file_path, "r", encoding="utf-8") as f:
                return HTMLResponse(content=f.read())
    
    # å¯¹äºå…¶ä»–è·¯å¾„ï¼Œè¿”å›index.htmlï¼ˆSPAè·¯ç”±ï¼‰
    index_path = os.path.join(dist_path, "index.html")
    if os.path.exists(index_path):
        with open(index_path, "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())
    else:
        return HTMLResponse(content="<h1>å‰ç«¯æ–‡ä»¶æœªæ‰¾åˆ°</h1><p>è¯·å…ˆæ„å»ºå‰ç«¯é¡¹ç›®: cd ui && pnpm build</p>")

# æ¸…ç†å‡½æ•°
import atexit
import shutil

def cleanup_temp_files():
    """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
    try:
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
            print(f"å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶ç›®å½•: {temp_dir}")
    except Exception as e:
        print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")

atexit.register(cleanup_temp_files)

if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸš€ GPT-SoVITS TTS æœåŠ¡å¯åŠ¨ä¸­...")
    print("="*60)
    print(f"ğŸ“¡ APIæœåŠ¡åœ°å€: http://localhost:8000")
    print(f"ğŸ“š APIæ–‡æ¡£åœ°å€: http://localhost:8000/docs")
    if os.path.exists(dist_path):
        print(f"ğŸ¨ å‰ç«¯ç•Œé¢åœ°å€: http://localhost:8000")
    else:
        print(f"âš ï¸  å‰ç«¯æœªæ„å»ºï¼Œè¯·è¿è¡Œ: cd ui && pnpm build")
    print("="*60)
    print("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡\n")
    
    uvicorn.run(app, host="0.0.0.0", port=8000) 